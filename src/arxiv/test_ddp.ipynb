{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils.data import Dataset\n",
    "dev = torch.device(\"cuda\")\n",
    "import torch.optim as optim\n",
    "root_dir = '/mnt/home/spandey/ceph/CHARFORMER/'\n",
    "os.chdir(root_dir)\n",
    "# import colossus\n",
    "import pickle as pk\n",
    "# append the root_dir to the path\n",
    "sys.path.append(root_dir)\n",
    "from src.model_enc_dec import *\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from dataclasses import dataclass\n",
    "from contextlib import nullcontext\n",
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32', 'bfloat16', or 'float16', the latter will auto implement a GradScaler\n",
    "# dtype = 'float32'\n",
    "# if master_process:\n",
    "    # os.makedirs(out_dir, exist_ok=True)\n",
    "from dataclasses import dataclass\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "\n",
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "    # initialize the process group\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X_halo, X_DM, MASK_halo, Y_pred):\n",
    "        self.X1 = X_halo\n",
    "        self.X2 = X_DM\n",
    "        self.MASK_X1 = MASK_halo        \n",
    "        self.Y = Y_pred\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X1[index], self.X2[index], self.MASK_X1[index], self.Y[index]\n",
    "\n",
    "    def __iter__(self):\n",
    "        start = self.rank * (len(self) // self.world_size)\n",
    "        end = start + (len(self) // self.world_size)\n",
    "        return iter(range(start, end))\n",
    "\n",
    "    def set_rank_and_world_size(self, rank, world_size):\n",
    "        self.rank = rank\n",
    "        self.world_size = world_size\n",
    "\n",
    "    def set_epoch(self, epoch):\n",
    "        # Optionally shuffle your data for each epoch\n",
    "        pass\n",
    "\n",
    "\n",
    "def get_data_split(dfhalo_ngp_xyzM_tokenized_padded_ended_squeezed, delta_box_all_squeezed, n1_fac=0.8, n2_fac=1.0):\n",
    "    n1 = int(n1_fac*len(dfhalo_ngp_xyzM_tokenized_padded_ended_squeezed)) # first 90% will be train, rest val\n",
    "    n2 = int(n2_fac*len(dfhalo_ngp_xyzM_tokenized_padded_ended_squeezed)) # first 90% will be train, rest val\n",
    "    train_data_halos = dfhalo_ngp_xyzM_tokenized_padded_ended_squeezed[:n1]\n",
    "    val_data_halos = dfhalo_ngp_xyzM_tokenized_padded_ended_squeezed[n1:n2]\n",
    "\n",
    "    train_data_dm = delta_box_all_squeezed[:n1]\n",
    "    val_data_dm = delta_box_all_squeezed[n1:n2]\n",
    "\n",
    "    x = torch.tensor(train_data_halos[:, :-1])\n",
    "    y = torch.tensor(train_data_halos[:, 1:])\n",
    "    dm = torch.tensor(train_data_dm)\n",
    "    mask_train_orig = x != 1\n",
    "    mask_train = torch.logical_not(mask_train_orig)\n",
    "    masked_logits = torch.zeros(mask_train.shape)\n",
    "    mask_train_final = masked_logits.masked_fill(mask_train, float('-inf'))\n",
    "    mask_train = mask_train_final[:,None,:]\n",
    "    x, y = torch.tensor(x), torch.tensor(y)\n",
    "    x_train = x.long()\n",
    "    y_train = y.long()\n",
    "    dm_train = dm.bfloat16()\n",
    "    mask_train = torch.tensor(mask_train).bfloat16()\n",
    "\n",
    "    x = torch.tensor(val_data_halos[:, :-1])\n",
    "    y = torch.tensor(val_data_halos[:, 1:])\n",
    "    dm = torch.tensor(val_data_dm)\n",
    "    mask_val_orig = x != 1\n",
    "    mask_val = torch.logical_not(mask_val_orig)\n",
    "    masked_logits = torch.zeros(mask_val.shape)\n",
    "    mask_val_final = masked_logits.masked_fill(mask_val, float('-inf'))\n",
    "    mask_val = mask_val_final[:,None,:]\n",
    "    x, y = torch.tensor(x), torch.tensor(y)\n",
    "    x_val = x.long()\n",
    "    y_val = y.long()\n",
    "    dm_val = dm.bfloat16()\n",
    "    mask_val = torch.tensor(mask_val).bfloat16()\n",
    "\n",
    "    return x_train, y_train, dm_train, mask_train, x_val, y_val, dm_val, mask_val\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "# if __name__ == '__main__':\n",
    "    # hyperparameters\n",
    "    # batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "    # block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 10\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 48\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.2\n",
    "# ------------\n",
    "vocab_size = 131\n",
    "block_size = 161\n",
    "batch_size = 1024\n",
    "\n",
    "# n_embd_dm = 64\n",
    "# n_head_dm = 4\n",
    "# n_layer_dm = 3\n",
    "# dropout_dm = 0.2\n",
    "# vocab_size_dm = 3\n",
    "# block_size_dm = dm_train.shape[1]\n",
    "# batch_size = 2048\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class HaloConfig:\n",
    "    block_size: int = block_size\n",
    "    vocab_size: int = vocab_size\n",
    "    n_layer: int = n_layer\n",
    "    n_head: int = n_head\n",
    "    n_embd: int = n_embd\n",
    "    dropout: float = dropout\n",
    "    bias: bool = True # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n",
    "\n",
    "    ksize : int = 3\n",
    "    density_grid_in : int = 32\n",
    "    density_grid_out : int = 4\n",
    "    ninp_density : int = 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fn(rank, world_size):\n",
    "    # Initialize process group\n",
    "    dist.init_process_group(backend='nccl',rank=rank, world_size=world_size)\n",
    "    \n",
    "    # Set up random seeds\n",
    "    # torch.manual_seed(0)\n",
    "    torch.manual_seed(1337)\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
    "    torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n",
    "    # device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n",
    "    device_type = 'cuda' \n",
    "    # note: float16 data type will automatically use a GradScaler\n",
    "    ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "    ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
    "\n",
    "    \n",
    "    f = h5.File('/mnt/home/spandey/ceph/CHARFORMER/data/df_halo_part_ngp_xyzM_tokenized_density3Dgrid_32_isim_012_snap_3.h5', 'r')\n",
    "    dfhalo_ngp_xyzM_tokenized_padded_ended_squeezed_all = f['dfhalo_ngp_xyzM_tokenized_padded_ended_squeezed_all'][:]\n",
    "    delta_box_all_squeezed_all = f['delta_box_all_squeezed_all'][:]\n",
    "    f.close()\n",
    "\n",
    "    x_train, y_train, dm_train, mask_train, x_val, y_val, dm_val, mask_val = get_data_split(dfhalo_ngp_xyzM_tokenized_padded_ended_squeezed_all, delta_box_all_squeezed_all, 0.05, 0.1)\n",
    "\n",
    "    start_token = 0\n",
    "    pad_token = 1\n",
    "    end_token = int(torch.max(x_train).cpu().numpy()) - 1\n",
    "    space_token = int(torch.max(x_train).cpu().numpy())\n",
    "\n",
    "\n",
    "    # Define model\n",
    "    # model = torchvision.models.resnet18()\n",
    "    \n",
    "    # Wrap model with DistributedDataParallel\n",
    "    # model = DistributedDataParallel(model)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Load data\n",
    "    train_dataset = CustomDataset(x_train, dm_train, mask_train, y_train)\n",
    "    train_dataset.set_rank_and_world_size(rank, world_size)\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset, num_replicas=world_size, rank=rank)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, sampler=train_sampler)\n",
    "\n",
    "    val_dataset = CustomDataset(x_val, dm_val, mask_val, y_val)\n",
    "    val_dataset.set_rank_and_world_size(rank, world_size)\n",
    "    val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset, num_replicas=world_size, rank=rank)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, sampler=val_sampler)\n",
    "\n",
    "    x_train_gpu, dm_train_gpu, mask_train_gpu, y_train_gpu = [], [], [], []\n",
    "    for x, dm, mask, y in train_loader:\n",
    "        x_train_gpu.append(x.cuda(non_blocking=True))\n",
    "        dm_train_gpu.append(dm.cuda(non_blocking=True))\n",
    "        mask_train_gpu.append(mask.cuda(non_blocking=True))\n",
    "        y_train_gpu.append(y.cuda(non_blocking=True))\n",
    "    \n",
    "    x_train_gpu = torch.cat(x_train_gpu, dim=0)\n",
    "    dm_train_gpu = torch.cat(dm_train_gpu, dim=0)\n",
    "    mask_train_gpu = torch.cat(mask_train_gpu, dim=0)\n",
    "    y_train_gpu = torch.cat(y_train_gpu, dim=0)\n",
    "\n",
    "    x_val_gpu, dm_val_gpu, mask_val_gpu, y_val_gpu = [], [], [], []\n",
    "    for x, dm, mask, y in val_loader:\n",
    "        x_val_gpu.append(x.cuda(non_blocking=True))\n",
    "        dm_val_gpu.append(dm.cuda(non_blocking=True))\n",
    "        mask_val_gpu.append(mask.cuda(non_blocking=True))\n",
    "        y_val_gpu.append(y.cuda(non_blocking=True))\n",
    "    \n",
    "    x_val_gpu = torch.cat(x_val_gpu, dim=0)\n",
    "    dm_val_gpu = torch.cat(dm_val_gpu, dim=0)\n",
    "    mask_val_gpu = torch.cat(mask_val_gpu, dim=0)\n",
    "    y_val_gpu = torch.cat(y_val_gpu, dim=0)\n",
    "\n",
    "    model = HaloDecoderModel(HaloConfig)\n",
    "    model.to(device).bfloat16()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    def get_batch(split, ji=0, batch_size=None):\n",
    "        if split == 'train':\n",
    "            x = x_train_gpu\n",
    "            y = y_train_gpu\n",
    "            mask = mask_train_gpu\n",
    "            dm = dm_train_gpu\n",
    "\n",
    "        elif split == 'val':\n",
    "            x = x_val_gpu\n",
    "            y = y_val_gpu\n",
    "            mask = mask_val_gpu\n",
    "            dm = dm_val_gpu\n",
    "\n",
    "        if batch_size is not None:\n",
    "            x = x[batch_size*(ji):batch_size*(ji+1)].to(device, non_blocking=True)\n",
    "            y = y[batch_size*(ji):batch_size*(ji+1)].to(device, non_blocking=True)\n",
    "            mask = mask[batch_size*(ji):batch_size*(ji+1)].to(device, non_blocking=True)\n",
    "            dm = dm[batch_size*(ji):batch_size*(ji+1)].to(device, non_blocking=True)\n",
    "\n",
    "        return x, y, mask, dm\n",
    "\n",
    "    # helps estimate an arbitrarily accurate loss over either split using many batches\n",
    "    def estimate_loss():\n",
    "        out = {}\n",
    "        # model.eval()\n",
    "        for split in ['train', 'val']:\n",
    "            losses = torch.zeros(eval_iters)\n",
    "            for k in range(eval_iters):\n",
    "                X, Y, MASK, DM = get_batch(split, batch_size = batch_size)\n",
    "                with ctx:\n",
    "                    logits, loss = model(X, DM, maskd=MASK, targets=Y)\n",
    "                losses[k] = loss.item()\n",
    "            out[split] = losses.mean()\n",
    "        return out\n",
    "\n",
    "    print(\"compiling the model... (takes a ~minute)\")\n",
    "    unoptimized_model = model\n",
    "    model = torch.compile(model) # requires PyTorch 2.0\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
    "\n",
    "    model.load_state_dict(torch.load('/mnt/home/spandey/ceph/CHARFORMER/model_checkpoints/model_encdec.pt'))\n",
    "\n",
    "    # Training loop\n",
    "    val_loss_min = 1e20\n",
    "    # saved = {}\n",
    "    eval_interval = 40\n",
    "    nbatches = 24\n",
    "    saved = {}\n",
    "    for iter in range(max_iters):\n",
    "\n",
    "        # every once in a while evaluate the loss on train and val sets\n",
    "        if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "            with torch.no_grad():\n",
    "                losses = estimate_loss()\n",
    "                print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "                # save the model if it's better than the previous best:\n",
    "                if losses['val'] < val_loss_min:\n",
    "                    val_loss_min = losses['val']\n",
    "                    checkpoint = {\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'best_loss': val_loss_min,\n",
    "                        'epoch': iter\n",
    "                    }\n",
    "                    if rank == 0:\n",
    "                        # torch.save(model.state_dict(), '/mnt/home/spandey/ceph/CHARFORMER/model_checkpoints/model_encdec.pt')\n",
    "                        torch.save(checkpoint, '/mnt/home/spandey/ceph/CHARFORMER/model_checkpoints/model_encdec_testddp.pt')            \n",
    "                        print(f\"New best model saved with loss {val_loss_min:.4f}\")\n",
    "                    dist.barrier()\n",
    "\n",
    "        for ji in (range(nbatches)):\n",
    "            X, Y, MASK, DM = get_batch('train', ji, batch_size)\n",
    "            # with ctx:\n",
    "            _, loss = model(X, DM, maskd=MASK, targets=Y)\n",
    "                # loss = loss\n",
    "            # backward pass, with gradient scaling if training in fp16\n",
    "            scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        # flush the gradients as soon as we can, no need for this memory anymore\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        if iter % 10 == 0:\n",
    "            print(f\"iter {iter}, loss: {loss.item()}\")\n",
    "        # optimizer.zero_grad(set_to_none=True)\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Cleanup\n",
    "    dist.destroy_process_group()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/mnt/home/spandey/miniconda3/envs/ili-sbi/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/mnt/home/spandey/miniconda3/envs/ili-sbi/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'run_fn' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "ProcessExitedException",
     "evalue": "process 0 terminated with exit code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessExitedException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m world_size \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()  \u001b[38;5;66;03m# Use all available GPUs\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(world_size)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ili-sbi/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:281\u001b[0m, in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    275\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis method only supports start_method=spawn (got: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use a different start_method use:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m start_method\n\u001b[1;32m    279\u001b[0m     )\n\u001b[1;32m    280\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdaemon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspawn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ili-sbi/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:237\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ili-sbi/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:177\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[1;32m    170\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with signal \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (error_index, name),\n\u001b[1;32m    171\u001b[0m             error_index\u001b[38;5;241m=\u001b[39merror_index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m             signal_name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    175\u001b[0m         )\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[1;32m    178\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with exit code \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (error_index, exitcode),\n\u001b[1;32m    179\u001b[0m             error_index\u001b[38;5;241m=\u001b[39merror_index,\n\u001b[1;32m    180\u001b[0m             error_pid\u001b[38;5;241m=\u001b[39mfailed_process\u001b[38;5;241m.\u001b[39mpid,\n\u001b[1;32m    181\u001b[0m             exit_code\u001b[38;5;241m=\u001b[39mexitcode,\n\u001b[1;32m    182\u001b[0m         )\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_files[error_index], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m    185\u001b[0m     original_trace \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(fh)\n",
      "\u001b[0;31mProcessExitedException\u001b[0m: process 0 terminated with exit code 1"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "world_size = torch.cuda.device_count()  # Use all available GPUs\n",
    "print(world_size)\n",
    "\n",
    "mp.spawn(run_fn, args=(world_size,), nprocs=world_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/mnt/home/spandey/miniconda3/envs/ili-sbi/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/mnt/home/spandey/miniconda3/envs/ili-sbi/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'run_fn' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "ProcessExitedException",
     "evalue": "process 0 terminated with exit code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessExitedException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHaloConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ili-sbi/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:281\u001b[0m, in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    275\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis method only supports start_method=spawn (got: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use a different start_method use:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m start_method\n\u001b[1;32m    279\u001b[0m     )\n\u001b[1;32m    280\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdaemon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspawn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ili-sbi/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:237\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ili-sbi/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:177\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[1;32m    170\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with signal \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (error_index, name),\n\u001b[1;32m    171\u001b[0m             error_index\u001b[38;5;241m=\u001b[39merror_index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m             signal_name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    175\u001b[0m         )\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[1;32m    178\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with exit code \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (error_index, exitcode),\n\u001b[1;32m    179\u001b[0m             error_index\u001b[38;5;241m=\u001b[39merror_index,\n\u001b[1;32m    180\u001b[0m             error_pid\u001b[38;5;241m=\u001b[39mfailed_process\u001b[38;5;241m.\u001b[39mpid,\n\u001b[1;32m    181\u001b[0m             exit_code\u001b[38;5;241m=\u001b[39mexitcode,\n\u001b[1;32m    182\u001b[0m         )\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_files[error_index], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m    185\u001b[0m     original_trace \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(fh)\n",
      "\u001b[0;31mProcessExitedException\u001b[0m: process 0 terminated with exit code 1"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ili-sbi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
